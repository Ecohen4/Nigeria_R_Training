Before getting started
=======

We recommend watch the following video before reading this document
* [Video tutorial for R from Google Developer](http://www.youtube.com/watch?v=iffR3fWv4xw&list=PLOU2XLYxmsIK9qQfztXeybpHvru-TrqAP)

Basic R
========================================================

Getting started
----
### Interface of Rstudio

![alt text][R_studio]

[R_studio]: https://lh3.googleusercontent.com/-fFe1VlFiVzA/TWvS0Cuvc3I/AAAAAAAALmk/RfFLB0h5dUM/s1600/rstudio-windows.png

Items:
* Console
* Script
* Environment (will make sense later)
* Help, Plots

### Working directory 

R has a notion of a "working directory". This is the directory that R can load files directly from.

```{r}
# getting the current working directory 
getwd()
```

```{r echo=TRUE, eval=FALSE}
### setting "my working directory" as "~/work/r/nigeria_r_training/"
setwd("~/work/r/nigeria_r_training/")
```

### Getting help!

Before we get any further, lets see how to get help. You can go to the "Help" tab in R-studio (right-hand-side bottom), or if you know the function to get help on, just use a question mark followed by the function name.
```{r}
?getwd
```

Use two question marks to search for functions if you don't know the name:
```{r}
??workingdirectory
```

### Reading data: read.csv

.csv is the prefered data format in NMIS and in the data science space in general. Although there are functions in R to read other data formats, we recommend that one converts to csv prior to loading. Our motivations for using csv formats are similar to [this article's](http://dataprotocols.org/simple-data-format/#why-csv).

```{r}
sample_data <- read.csv("sample_health_facilities.csv", stringsAsFactors=FALSE)
```

This command calls read.csv on a filename, with an extra named argument, `stringsAsFactors`. The result is then assigned to sample_data. This command is equivalent to running `sample_data = read.csv(sample_health_facilities.csv, stringsAsFactors=FALSE)`, but the preferred syntax for assignment in R is `<-` (ie, `<` followed by `-`.)

### The sample dataset

The dataset is a subset of our health dataset. We're providing you with a small piece of it, so that we can begin to understand things with small datasets, and eventually move on to the bigger datasets that we handle in the NMIS system.

Have a look at the dataset on [https://github.com/SEL-Columbia/Nigeria_R_Training/blob/master/sample_health_facilities.csv](github), or open it in your favorite spreadsheet program (Excel, OpenOffice).


data.frame
--------------
CSVs represent tabular data, which R is excellent at handling. Turns out that the data we have for NMIS is also tabular data, so we will be working with data.frames in R most of the time.

`sample_data`, the object we created by reading in a CSV, is a data.frame. Look at the top-left side of Rstudio. You can open up the dataset by clicking on it.

A data.frame is made up of rows and columns. Lets get the "dimensions" of the data.frame:

```{r}
dim(sample_data)
```

This shows that that `sample_data` has `{r} nrow(sample_data)` rows and `{r ncol(sample_data) }` columns. The functions `nrow` and `ncol` can give you these values individually:

```{r}
nrow(sample_data)
ncol(sample_data)
```

### Displaying the data.frame

After loading the data.frame, we often want to know what columns are in it (columns usually have names). To check the column names of a dataset, we can use the `colnames` function, or more simply, the `names` function:

```{r message=FALSE, echo=TRUE, eval=FALSE}
names(sample_data)
```

But that just shows us the "headers" of our dataset, not the values. What happens if you just type sample_data into the console? Often, seeing the whole dataset is too much. But it is easy to "take a peek" at your dataset by using `head` (which UNIX users may have heard of already):

```{r}
head(sample_data)
```


Questions:
 * How many rows of data did we get out?
 * Did you count to get your answer? If you did, how could you get your answer from R?
 * How many columns of data did we get out? How would you check in R?
 * Could you change the number of rows that head outputs? How would you find out?
 * Can you create a new data.frame, called `small_sample`, which is just the first 10 rows of `sample_data`?

### getting value/column from a data.frame
* a column in our data set is equavilent to a question in the survey
 1. using "$" operator
 2. calling column by it's name directly
 3. note: using head() to show only the first nth elements
```{r echo=TRUE, eval=FALSE}
sample_data$lga

sample_data[, "lga"]
```

```{r echo=FALSE, eval=TRUE}
head(sample_data$lga, 10)

head(sample_data[, "lga"], 10)
```
* We generally prefer the first strategy, but sometimes we'll need to use the second strategy. Note that spellings have to be exact, and when using the $ notation, you can use tab completion. Try writing sample_data$l and hitting tab, for example. 

### Data types: 
  1. numerical
  2. integer
  3. boolean
  4. character
  5. factors
    * generic data type used as alternative to all of the above. we recommend __not__ using. 
    * specifically, there are typically challenges with factor => integer/numeric conversions
    * for additional information on working with factors in your data: [More information on Factors](http://www.statmethods.net/input/datatypes.html)

  6. NA
    * an additional data type in R for value __NOT AVAILABLE__, which can be found in any of the data type above


### getting row content by calling the row number
 * a row in our data set is equavilent to one full survey i.e. one facility
 * note: index in R starts at 1 instead of 0
```{r echo=TRUE, eval=FALSE}
sample_data[2, ]
```
```{r echo=FALSE, eval=TRUE}
sample_data[2, ][1:10]
```
### more slicing and dicing in R
* getting the element in 4th row and 5th column
```{r}
sample_data[4, 5]
```

* getting the elements from 4th to 6th row and column 1 to column 5(inclusive)
```{r}
sample_data[4:6, 1:5]
```

### exploring the data frame with some useful functions
* getting the structure
```{r echo=TRUE, eval=FALSE}
str(sample_data)
```

* getting the dimension of data.frame
```{r echo=TRUE, eval=TRUE}
dim(sample_data)
```

* getting the class of specific column

  * note: class is the type of things in R. In python, this is equivalent to calling type(obj). In javascript, you would use typeof

```{r}
class(sample_data$lga)

class(sample_data[, 1])

class(sample_data[, "lga"])
```

* getting the summary/descriptive statistics 

  * __table()__ should be used for character and string variables
  * __summary()__ should be used for numerical or boolean variables
```{r echo=TRUE, eval=FALSE}
table(sample_data$zone)
```
  
```{r echo=FALSE, eval=TRUE}
table(sample_data$zone)
```

```{r echo=TRUE, eval=FALSE}
summary(sample_data$num_nurses_fulltime)
```
  
```{r echo=FALSE, eval=TRUE}
summary(sample_data$num_nurses_fulltime)
```

### libraries
 * install packages
 * to install packges in R, call __install.packages()__ with quoted package name: 
```{r echo=TRUE, eval=FALSE}
install.packages("plyr")
```   
 * to load libraries in R call __library()__ fucntion
  
```{r}
library(plyr)
```
  * libraries are additional packages to R that contain additional specialized functions 
  * plyr library is used for aggregating data, which will be explored in detail later

* be sure that the package you are trying to load is installed on your computer
```{r}
library(eaf)
```


creating data frames
---------------------

### joining columns:
* R supports SQL-like join functionality with merge()
  *first we'll prepare the data for a merge
```{r, echo=FALSE}
data1 <- subset(sample_data, select=-c(zone, gps))
```

```{r echo=TRUE, eval=TRUE}
head(data1)
```

```{r, echo=FALSE}
data2 <- unique(subset(sample_data, select=c(state, zone), subset=zone != "Southeast"))

```

```{r echo=TRUE, eval=TRUE}
head(data2)
```

* inner join
```{r}
inner_join <- merge(data1, data2, by="state")
```

* outer join
```{r}
outer_join <- merge(data1, data2, by="state", all=TRUE)
```

* left outer join
```{r}
left_outer_join <- merge(data1, data2, by.x="lga_id",
                    by.y="lga_id",all.x=TRUE)
```

* concatenate data.frames COLUMNwise with cbind()
* note that the order of rows in original data is unchanged
```{r, echo=TRUE, eval=FALSE}
cbind(data1, data2)
```
```{r, echo=FALSE, eval=TRUE}
cbind(data1, data2)[1:10,1:10]
```


* concatenate data.frames ROWise with cbind()
* note that the order of columns in original data is unchanged
```{r}
data4 <- sample_data[1:5, ]
data5 <- sample_data[6:10, ]
```

```{r, echo=TRUE, eval=FALSE}
rbind(data4, data5)
```
```{r, echo=FALSE, eval=TRUE}
rbind(data4, data5)[1:10,1:10]
```
* use with care: make sure your columns alligns before using, and here is an example of misuse
```{r, echo=TRUE, eval=FALSE}
rbind(data1, data2)
```
```{r, echo=FALSE, eval=TRUE}
rbind(data1, data2)[1:10,1:10]
```
* rbind.fill() is a powerful rbind() realization in __plyr__ package
* with rbind you have to make every column in both data.frames exist and allign(have the same index number), but with rbind.fill you need not be concerned. 
* rbind.fill() finds the corresponding column in data.frame2 and concatenate the data, and if there's no corresponding part it assigns __*NA*__
```{r echo=TRUE, eval=FALSE}
rbind.fill(data1, data2)
```
```{r echo=FALSE, eval=TRUE}
rbind.fill(data1, data2)[1:10, 1:10]
```

### creating derivative data frames via subset:
* getting a subset of original data with a handy functions saves a lot of typing

```{r}
subset(sample_data, lga_id < 500, select=c("lga_id", "lga", "state" ))
```

data cleaning:
----

### type conversion
* type conversion can be forced by __as.\*()__ function
* common __\*__ types you'd encounter are: 
  1. numeric
  2. integer
  3. character
  4. logical
* sometimes you'll encounter __factor__ variables, we recommend using __as.character()__ function to convert it into character type before proceeding 

* here's some examples
```{r}
my_numbers <- c("1", "2", "3", "4", "5")
my_numbers
as.numeric(my_numbers)
```

creating and deleting columns
--------------

* creating a column from a vector 
```{r}
sample_data$simple <- 1:50
#a head() of the newly created simple column:
```

```{r, echo=FALSE, eval=TRUE}
head(sample_data$simple)
```
* column creation: __broadcasting__  
  * R makes column creation very straightforward by repeating a value which is known as "broadcasting"
```{r}
sample_data$simple <- "who wants some egusi?"
#a head() of the newly defined simple column:
```

```{r, echo=FALSE, eval=TRUE}
head(sample_data$simple)
```

* creating a column from a single value
  * R allows the user to broadcast numerical values as well
```{r}
sample_data$simple <- 1963
#a head() of the newly defined simple column
```

```{r, echo=FALSE, eval=TRUE}
head(sample_data$simple)
```
  
* column creation: using already existing columns
```{r}
#a look at the lga column 
head(sample_data$lga_id)
#creating a new column, by pasting "9ja:" to the values of the lga column
sample_data$lga_id_national <- paste("9ja:", sample_data$lga_id, sep = "")
#a look at the the new lga_id_national column
head(sample_data$lga_id_national)
```

* column creation: boolean columns
```{r}
sample_data$public <- sample_data$management == "public"
head(sample_data[, c("management", "public")])

sample_data$public_2_docs <- sample_data$management == "public" & sample_data$num_doctors_fulltime == 2
head(sample_data[, c("public_2_docs", "management", "public")]) 
  
```

* renaming  	
```{r}
#quote the current variable name, and set it equal the quoted desired name  
sample_data <- rename(sample_data, c("gps" = "global_positioning_system"))
```

* removing columns
```{r}
sample_data$num_nurselabtechs_fulltime <- NULL
#testing to make sure it no longer exists
summary(sample_data$num_nurselabtechs_fulltime)
```
 
data cleaning
--------------
### string manipulations
* we're going to cover regex suite comes with base R, string_r packages have similar implementations.
* we're not going to cover regex/ regular expression in this tuorial.
* getting position of matched pattern with grep()
```{r}
my_strings = c("Hello", "World", 'Foo')
grep(pattern="l", x=my_strings, ignore.case=FALSE)
#when value argument is set to true, grep() returns the actual strings matchs the patterns
grep(pattern="l", x=my_strings, ignore.case=FALSE, value=T)
```
* find pattern in strings and replace with sub()
* gsub() means global sub, which replace all the occurance of matching pattern, while sub() only works on the first appearance.
```{r}
my_strings
sub(pattern="o", replacement="X", x=my_strings)
gsub(pattern="o", replacement="X", x=my_strings)
```
* change to upper/lower case with toupper()/ tolower()
```{r}
my_strings
toupper(my_strings)
tolower(my_strings)
```
* concatenate strings with paste():
```{r}
paste("hello", "world", "foo", sep=",")
```
* if you're trying to concate every element in a vector/ list, use __collapse__ argument in paste()
```{r}
paste(my_strings, sep=',')
paste(my_strings, collapse=',')
```

### writing out data
* R can output multiple different output format, but we're going to cover csv and RDS format
* writing csv file with write.csv()
 * if you find output row.names everytime annoying, set row.names argument to FALSE in write.csv()
```{r}
write.csv(sample_data, "./my_output.csv", row.names=FALSE)
```
* we recommend output your data as RDS file, if you're only going to reuse it in R.
* use saveRDS() to save object in workspace to your harddrive
  * no row.names argument needs to be used, since we're saving the R object into a binary file
```{r}
saveRDS(sample_data, "./my_output.RDS")
```
* use readRDS() function to load saved RDS file
```{r echo=TRUE, eval=FALSE}
readRDS("./my_output.RDS")
```
```{r echo=FALSE, eval=TRUE}
readRDS("./my_output.RDS")[1:10, 1:10]
```

Aggregations in R:
----
* there are many functions that can do aggregation for you, but we are only going to cover __ddply()__ in __plyr__ package

* creating simple aggregated summary:
* note: 
  1. __(group) by__ variable must have at least one input
  2. you __must__ specify what type of aggregation you want to perform, choose one from: summarize, transform
* [the link to the package dodument](http://cran.r-project.org/web/packages/plyr/plyr.pdf)
```{r}
library(plyr)
my_summary <- ddply(sample_data, .(state, lga), summarise, 
                    counts = length(lga_id),
                    total_num_nurse = sum(num_nurses_fulltime, na.rm=T),
                    avg_c_section = mean(c_section_yn == T,na.rm=T))
head(my_summary)
```
* look at the output and compare the difference, the only change here is replacing summarize with transform
```{r}
my_summary <- ddply(sample_data, .(state, lga), transform, 
                    counts = length(lga_id),
                    total_num_nurse = sum(num_nurses_fulltime, na.rm=T),
                    avg_c_section = mean(c_section_yn == T,na.rm=T))
head(my_summary)
```

Advanced R
========================================================

creation of more complex columns(indicators) with __rowSums()__:
-------------------------------------
* column creation: sum of multiple numerical columns 
```{r}
sample_data$num_nurselabtechs_fulltime <- rowSums(cbind(sample_data$num_nurses_fulltime,
                                            sample_data$num_lab_techs_fulltime, na.rm = T))
```
  
```{r}
#now we can view all three variables: the new num_nurselabtechs_fulltime variable, and the two used to create it
head(subset(sample_data, select=c("num_nurses_fulltime", "num_lab_techs_fulltime", "num_nurselabtechs_fulltime")), 5)
```

creation of more complex columns(indicators) with __ifelse()__:
-------------------------------------


install packages from outside of cran
-------------------------------------
* in order to install packages on github we need some extra work
* this tutorial will use the example of formhub.R
* first step: install and load __devtools__ package from cran
```{r}
install.packages('devtools') 
library(devtools)
```
* second step: use __install_github("repo_name", "user_name")__ function to install packages on github
```{r}
install_github("formhub.R", username="SEL-Columbia")
library(formhub)
```

map functions: apply()
-----------------------
* instead of using for loops, we encourage using map. The apply/sapply is the implementation of map in R
* Here's the simply example for using apply to loop through every column and see the class of the column
  * note: __MARGIN = 2__ specifies doing column-wise process
```{r echo=TRUE, eval=FALSE}
apply(sample_data, MARGIN=2, FUN=class)
```
```{r echo=FALSE, eval=TRUE}
apply(sample_data, MARGIN=2, FUN=class)[1:10]
```

* you can also define your own function in apply()
* the following code returns sum of __NAs__ in each row
  * note: when you're define your own function in apply use semi-colon as the line marker.
  * note: __MARGIN = 1__ specifies doing row-wise process
```{r echo=TRUE, eval=FALSE}
apply(sample_data, MARGIN=1, function(x) {
  na_idx <- is.na(x);
  length(which(na_idx))
})
```
```{r echo=FALSE, eval=TRUE}
apply(sample_data, MARGIN=1, function(x) {
  na_idx <- is.na(x);
  length(which(na_idx))
  })[1:10]
```

improvements:
-----------------
* load your own functions into workspace with source()
```{r}
source("./my_source_functions.R")
my_sum(1,2)
```

* optimize ddply with idata.frame()
 * idata.frame optimizes the computation speed but at the cost of a slight more complicated code





